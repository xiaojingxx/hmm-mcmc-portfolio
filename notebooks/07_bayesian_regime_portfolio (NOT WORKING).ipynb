{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d600c7d-a08c-450d-80bc-566dc334278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import pytensor.tensor as pt\n",
    "from pytensor.scan import scan\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9220362-9256-4178-b275-d38c04b830a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Folder where your files are\n",
    "folder = \"../data/processed\"\n",
    "\n",
    "# Pattern to match 'hmm_<asset>' at the start of the filename\n",
    "pattern = re.compile(r'hmm_([A-Za-z0-9]+)')\n",
    "\n",
    "# Find all CSV files starting with \"hmm_\"\n",
    "files = glob.glob(os.path.join(folder, \"hmm_*.csv\"))\n",
    "\n",
    "returns = []\n",
    "\n",
    "for file in files:\n",
    "    filename = os.path.basename(file)\n",
    "    match = pattern.match(filename)\n",
    "    if match:\n",
    "        asset = match.group(1)\n",
    "        df = pd.read_csv(\n",
    "            file,\n",
    "            index_col=0,       # use first column as index\n",
    "            parse_dates=True   # parse index as datetime if possible\n",
    "        )\n",
    "        \n",
    "        returns.append(df[f\"{asset}_ret\"])\n",
    "\n",
    "portfolio_returns = (\n",
    "    pd.concat(returns, axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f57b8c85-0718-4d20-95cb-6f906fdba548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf3ef2d9-c1c4-4883-bd31-1eae3255d190",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_assets = len(portfolio_returns.columns)\n",
    "num_regimes = 2\n",
    "T = len(portfolio_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e207b39-be1c-4358-9533-9a42d9f980c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pymc' has no attribute 'CategoricalHMM'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     30\u001b[39m sigma = pm.Deterministic(\u001b[33m\"\u001b[39m\u001b[33msigma\u001b[39m\u001b[33m\"\u001b[39m, pt.stack([pt.dot(chol, chol.T) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_regimes)]))\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# --- Hidden regimes z_t ---\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Categorical latent variable with Markov dependency\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m z = \u001b[43mpm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCategoricalHMM\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33mz\u001b[39m\u001b[33m\"\u001b[39m, P=P, pi0=pi0, shape=T)\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# --- Observation model ---\u001b[39;00m\n\u001b[32m     37\u001b[39m obs = pm.MvNormal(\n\u001b[32m     38\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mobs\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     39\u001b[39m     mu=mu[z],\n\u001b[32m     40\u001b[39m     chol=chol,  \u001b[38;5;66;03m# use cholesky for multivariate normal\u001b[39;00m\n\u001b[32m     41\u001b[39m     observed=returns_np\n\u001b[32m     42\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: module 'pymc' has no attribute 'CategoricalHMM'"
     ]
    }
   ],
   "source": [
    "import pymc as pm\n",
    "import pytensor.tensor as pt\n",
    "import numpy as np\n",
    "\n",
    "# ----------------------------\n",
    "# Inputs\n",
    "# ----------------------------\n",
    "# returns_np: (T, N) array of daily returns\n",
    "T, N = returns_np.shape\n",
    "num_regimes = 2  # e.g., low-volatility, high-volatility\n",
    "\n",
    "# ----------------------------\n",
    "# HMM Model\n",
    "# ----------------------------\n",
    "with pm.Model() as hmm_model:\n",
    "    \n",
    "    # --- Regime transition matrix ---\n",
    "    P = pm.Dirichlet(\"P\", a=np.ones((num_regimes, num_regimes)), shape=(num_regimes, num_regimes))\n",
    "    \n",
    "    # --- Initial regime probabilities ---\n",
    "    pi0 = pm.Dirichlet(\"pi0\", a=np.ones(num_regimes))\n",
    "    \n",
    "    # --- Regime-specific means and covariances ---\n",
    "    mu = pm.Normal(\"mu\", mu=0, sigma=0.01, shape=(num_regimes, N))\n",
    "    \n",
    "    sd_dist = pm.Exponential.dist(1.0, shape=N)\n",
    "    chol, corr, stds = pm.LKJCholeskyCov(\"chol_cov\", n=N, eta=2, sd_dist=sd_dist)\n",
    "    \n",
    "    # Compute full covariance matrices for each regime\n",
    "    sigma = pm.Deterministic(\"sigma\", pt.stack([pt.dot(chol, chol.T) for _ in range(num_regimes)]))\n",
    "    \n",
    "    # --- Hidden regimes z_t ---\n",
    "    # Categorical latent variable with Markov dependency\n",
    "    z = pm.CategoricalHMM(\"z\", P=P, pi0=pi0, shape=T)\n",
    "    \n",
    "    # --- Observation model ---\n",
    "    obs = pm.MvNormal(\n",
    "        \"obs\",\n",
    "        mu=mu[z],\n",
    "        chol=chol,  # use cholesky for multivariate normal\n",
    "        observed=returns_np\n",
    "    )\n",
    "    \n",
    "    # --- Sample ---\n",
    "    idata = pm.sample(chains=4, draws=2000, tune=2000, target_accept=0.95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa3ce30-ef77-4ee3-982c-ea2785fd9f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "idata.to_netcdf(\"bayes_hmm_portfolio.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5085a0-eeac-46cb-ac13-1e40cd4f0847",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9cd7db-0a51-46b1-bb9b-d98ed333ad3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# ----------------------------\n",
    "# Inputs\n",
    "# ----------------------------\n",
    "# returns_np: (T, N) array of daily returns\n",
    "# mu_t: (T, N) array of expected returns at each time\n",
    "# sigma_t: (T, N, N) array of full covariance matrices at each time\n",
    "\n",
    "T, N = returns_np.shape\n",
    "weights_t = np.zeros((T, N))\n",
    "port_ret_t = np.zeros(T)\n",
    "\n",
    "# ----------------------------\n",
    "# Sharpe-maximizing function\n",
    "# ----------------------------\n",
    "def sharpe_weights(mu, sigma):\n",
    "    # objective: negative Sharpe\n",
    "    def neg_sharpe(w):\n",
    "        port_mean = np.dot(w, mu)\n",
    "        port_var = np.dot(w, np.dot(sigma, w))\n",
    "        return -port_mean / np.sqrt(port_var)\n",
    "    \n",
    "    # constraints: sum(weights) = 1, weights >= 0\n",
    "    cons = ({'type': 'eq', 'fun': lambda w: np.sum(w) - 1})\n",
    "    bounds = [(0, 1) for _ in range(len(mu))]\n",
    "    \n",
    "    # initial guess: equal weight\n",
    "    w0 = np.ones(len(mu)) / len(mu)\n",
    "    res = minimize(neg_sharpe, w0, bounds=bounds, constraints=cons)\n",
    "    \n",
    "    return res.x\n",
    "\n",
    "# ----------------------------\n",
    "# Compute time-varying portfolio\n",
    "# ----------------------------\n",
    "for t in range(T):\n",
    "    # skip NaNs\n",
    "    if np.any(np.isnan(mu_t[t])) or np.any(np.isnan(sigma_t[t])):\n",
    "        weights_t[t] = np.nan\n",
    "        port_ret_t[t] = np.nan\n",
    "        continue\n",
    "    \n",
    "    w_t = sharpe_weights(mu_t[t], sigma_t[t])\n",
    "    weights_t[t] = w_t\n",
    "    port_ret_t[t] = np.dot(returns_np[t], w_t)\n",
    "\n",
    "# --\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf2ca6a-b0c9-4723-80da-7be973fa3675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ----------------------------\n",
    "# Compute portfolio returns\n",
    "# ----------------------------\n",
    "portfolio_returns = np.nansum(returns_np * weights_t, axis=1)\n",
    "valid_idx = ~np.isnan(portfolio_returns)\n",
    "portfolio_returns_clean = portfolio_returns[valid_idx]\n",
    "\n",
    "# Equal-weight benchmark\n",
    "benchmark_returns = np.mean(returns_np[valid_idx, :], axis=1)\n",
    "benchmark_returns_clean = benchmark_returns[~np.isnan(benchmark_returns)]\n",
    "\n",
    "# ----------------------------\n",
    "# Function to compute metrics\n",
    "# ----------------------------\n",
    "def compute_metrics(returns):\n",
    "    mean = returns.mean()\n",
    "    vol = returns.std()\n",
    "    sharpe = mean / vol * np.sqrt(252)\n",
    "    cum_returns = np.cumprod(1 + returns) - 1\n",
    "    max_drawdown = (cum_returns - np.maximum.accumulate(cum_returns)).min()\n",
    "    return mean, vol, sharpe, max_drawdown\n",
    "\n",
    "# ----------------------------\n",
    "# Metrics table\n",
    "# ----------------------------\n",
    "metrics = []\n",
    "metrics.append([\"HMM Portfolio\", *compute_metrics(portfolio_returns_clean)])\n",
    "metrics.append([\"Equal-Weight Benchmark\", *compute_metrics(benchmark_returns_clean)])\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics, columns=[\"Strategy\", \"Mean Return\", \"Volatility\", \"Annualized Sharpe\", \"Max Drawdown\"])\n",
    "print(metrics_df)\n",
    "\n",
    "# ----------------------------\n",
    "# Weight statistics table\n",
    "# ----------------------------\n",
    "weights_df = pd.DataFrame(weights_t, columns=[f\"Asset {i}\" for i in range(weights_t.shape[1])])\n",
    "weight_stats = pd.DataFrame({\n",
    "    \"Mean Weight\": weights_df.mean(),\n",
    "    \"Min Weight\": weights_df.min(),\n",
    "    \"Max Weight\": weights_df.max()\n",
    "})\n",
    "print(\"\\nWeight Statistics:\")\n",
    "print(weight_stats)\n",
    "\n",
    "# ----------------------------\n",
    "# Rolling Sharpe summary\n",
    "# ----------------------------\n",
    "rolling_window = 20\n",
    "rolling_mean = pd.Series(portfolio_returns_clean).rolling(rolling_window).mean()\n",
    "rolling_std = pd.Series(portfolio_returns_clean).rolling(rolling_window).std()\n",
    "rolling_sharpe = rolling_mean / rolling_std * np.sqrt(252)\n",
    "\n",
    "rolling_sharpe_stats = pd.DataFrame({\n",
    "    \"Rolling Sharpe (20d)\": [rolling_sharpe.min(), rolling_sharpe.mean(), rolling_sharpe.max()]\n",
    "}, index=[\"Min\", \"Mean\", \"Max\"])\n",
    "print(\"\\nRolling Sharpe (20-day) Statistics:\")\n",
    "print(rolling_sharpe_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eab079-2214-4bcc-935c-dc34b55896f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assume returns_np, weights_t, benchmark_idx as before\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Portfolio daily returns\n",
    "# ----------------------------\n",
    "portfolio_returns_2 = np.sum(returns_np * weights_t, axis=1)\n",
    "valid_idx = ~np.isnan(portfolio_returns)\n",
    "portfolio_returns_clean = portfolio_returns_2[valid_idx]\n",
    "\n",
    "benchmark_returns = np.mean(returns_np, axis=1)\n",
    "benchmark_returns_clean = benchmark_returns[~np.isnan(benchmark_returns)]\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Key metrics table\n",
    "# ----------------------------\n",
    "def compute_metrics(returns):\n",
    "    mean = returns.mean()\n",
    "    std = returns.std()\n",
    "    sharpe = mean / std * np.sqrt(252)\n",
    "    cum_returns = np.cumprod(1 + returns) - 1\n",
    "    max_drawdown = (cum_returns - np.maximum.accumulate(cum_returns)).min()\n",
    "    return mean, std, sharpe, max_drawdown\n",
    "\n",
    "metrics = []\n",
    "metrics.append([\"HMM Portfolio\", *compute_metrics(portfolio_returns_clean)])\n",
    "metrics.append([f\"Benchmark (Asset {benchmark_idx})\", *compute_metrics(benchmark_returns_clean)])\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics, columns=[\"Strategy\", \"Mean Return\", \"Volatility\", \"Annualized Sharpe\", \"Max Drawdown\"])\n",
    "print(metrics_df)\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Weight statistics table\n",
    "# ----------------------------\n",
    "weights_df = pd.DataFrame(weights_t, columns=[f\"Asset {i}\" for i in range(weights_t.shape[1])])\n",
    "weight_stats = pd.DataFrame({\n",
    "    \"Mean Weight\": weights_df.mean(),\n",
    "    \"Min Weight\": weights_df.min(),\n",
    "    \"Max Weight\": weights_df.max()\n",
    "})\n",
    "print(\"\\nWeight Statistics:\")\n",
    "print(weight_stats)\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Optional: Rolling Sharpe table\n",
    "# ----------------------------\n",
    "rolling_window = 20\n",
    "rolling_mean = pd.Series(portfolio_returns_clean).rolling(rolling_window).mean()\n",
    "rolling_std = pd.Series(portfolio_returns_clean).rolling(rolling_window).std()\n",
    "rolling_sharpe = rolling_mean / rolling_std * np.sqrt(252)\n",
    "\n",
    "rolling_sharpe_stats = pd.DataFrame({\n",
    "    \"Rolling Sharpe (20d)\": [rolling_sharpe.min(), rolling_sharpe.mean(), rolling_sharpe.max()]\n",
    "}, index=[\"Min\", \"Mean\", \"Max\"])\n",
    "\n",
    "print(\"\\nRolling Sharpe (20-day) Statistics:\")\n",
    "print(rolling_sharpe_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecc8523-9f1f-4434-85b2-383518a718ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "idata = az.from_netcdf(\"bayes_hmm_portfolio.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151f4d95-8ed1-4289-aa49-01aab773cdac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z_samples = idata.posterior[\"z\"].values  # (chains, draws, T) e.g., (2, 500, 2496)\n",
    "pi_t_posterior = np.zeros((T, num_regimes))  # (2496, 2)\n",
    "\n",
    "for k in range(num_regimes):\n",
    "    pi_t_posterior[:, k] = np.mean(z_samples == k, axis=(0, 1)) \n",
    "    \n",
    "mu_post = idata.posterior[\"mu\"].mean(('chain', 'draw')).values  # (regimes, assets)\n",
    "sigma_post = idata.posterior[\"sigma\"].mean(('chain', 'draw')).values ** 2  # variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d7a5bc-8b28-487f-8a04-39b05da7bfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpe_weights(mu_t, Sigma_t, leverage=1.0):\n",
    "    \"\"\"Analytical Sharpe-maximizing weights (full or diagonal Sigma_t).\"\"\"\n",
    "    try:\n",
    "        Sigma_inv = np.linalg.pinv(Sigma_t)\n",
    "        w = Sigma_inv @ mu_t\n",
    "        w = w / np.sum(np.abs(w)) * leverage\n",
    "        return w\n",
    "    except Exception:\n",
    "        return np.zeros(len(mu_t))\n",
    "\n",
    "weights_t = np.zeros((T, num_assets))\n",
    "port_sharpe_t = np.zeros(T)\n",
    "\n",
    "for t in range(T):\n",
    "    pi_t = pi_t_posterior[t, :]                    # (num_regimes,)\n",
    "    \n",
    "    # Mixture mean per asset\n",
    "    mu_t = np.sum(pi_t[:, None] * mu_post, axis=0)  # (N,)\n",
    "    \n",
    "    # Mixture *variance* per asset (diagonal)\n",
    "    var_t_diag = np.sum(pi_t[:, None] * sigma_post**2, axis=0)  # (N,)\n",
    "    \n",
    "    # Build diagonal covariance for the optimizer\n",
    "    Sigma_t = np.diag(var_t_diag)                  # (N, N)\n",
    "\n",
    "    # Sharpe-max weights\n",
    "    w_t = sharpe_weights(mu_t, Sigma_t)\n",
    "    weights_t[t] = w_t\n",
    "\n",
    "    # Realized Sharpe using diagonal variance\n",
    "    port_mu_t = w_t @ mu_t\n",
    "    port_var_t = np.sum((w_t**2) * var_t_diag)\n",
    "    port_sharpe_t[t] = port_mu_t / np.sqrt(port_var_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaf3782-346a-4b8f-b52c-51def9934a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== TIME-VARYING SHARPE PORTFOLIOS ===\")\n",
    "print(f\"Current regime probs: [{pi_t_posterior[-1,0]:.1%}, {pi_t_posterior[-1,1]:.1%}]\")\n",
    "print(\"\\nCurrent weights:\", weights_t[-1])\n",
    "print(f\"Current Sharpe: {port_sharpe_t[-1]:.3f}\")\n",
    "\n",
    "print(\"\\nWeight evolution (first → last):\")\n",
    "for i, name in enumerate(portfolio_returns.columns):\n",
    "    print(f\"{name}: {weights_t[0, i]:.3f} → {weights_t[-1, i]:.3f}\")\n",
    "\n",
    "print(f\"\\nSharpe evolution: {port_sharpe_t[0]:.2f} → {port_sharpe_t[-1]:.2f}\")\n",
    "print(f\"Max Sharpe: {port_sharpe_t.max():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b0ce89-9ecd-4987-b04a-e1e8a3141586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(port_sharpe_t, label=\"Sharpe over time\")\n",
    "plt.legend()\n",
    "plt.title(\"Time-Varying Sharpe\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "for i, a in enumerate(portfolio_returns.columns):\n",
    "    plt.plot(weights_t[:,i], label=a)\n",
    "plt.legend()\n",
    "plt.title(\"Bayesian Regime-Conditional Weights\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657e9fb7-0b01-4054-9b9e-51eae1b0ece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../data/processed/bayesian_weights.npy\", weights_t)\n",
    "np.save(\"../data/processed/bayesian_regime_probs.npy\", pi_t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:quant]",
   "language": "python",
   "name": "conda-env-quant-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
